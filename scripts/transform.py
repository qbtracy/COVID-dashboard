# -*- coding: utf-8 -*-
"""
This is the script for processing/data cleaning of the raw data files.

The majority of the code here was generated by ChatGPT, with tweaks made where needed to update info.
"""

import pandas as pd
from pathlib import Path

#(I need to test, but I havea feeling this will try to make a combined .csv out of every day's .csv)
#(I think I'll either need a way to just append new rows to the first raw data download, or something else)
raw_file = max(Path("data/raw").glob("data_*.csv"))
df = pd.read_csv(raw_file)

#Cleaning (possibly expand later if other issues identified)

#Fill missing values with -99 
df.fillna(value=-99)

# Example cleaning
#df.columns = df.columns.str.lower().str.replace(" ", "_")  
#df = df.drop_duplicates()                                   #These aren't (known) issues with this dataset
#df["date"] = pd.to_datetime(df["date"], errors="coerce")

output_path = Path("data/processed/clean_data.csv")
output_path.parent.mkdir(exist_ok=True)

df.to_csv(output_path, index=False)

print("Data cleaned and saved")